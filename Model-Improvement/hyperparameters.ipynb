{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c6ef94",
   "metadata": {},
   "source": [
    "### Hiperparámetros\n",
    "\n",
    "¿Qué son los hiperparámetros y cómo pueden ayudarnos a escoger el mejor modelo? ¿En qué se diferencian los hiperparámetros y los parámetros regulares?\n",
    "\n",
    "¿De qué depende la exactitud de las predicciones del árbol de decisión? Del número y de las posiciones relativas de los nodos (estructura), de la pregunta en la parte superior y de las respuestas en los nodos inferiores. El modelo adopta todos estos parámetros del conjunto de entrenamiento (no confundir con parámetros en Python).\n",
    "\n",
    "Además de los parámetros de modelo regulares, tenemos hiperparámetros. Estos son configuraciones para algoritmos de aprendizaje. Por ejemplo, en el árbol de decisión, uno de los ejemplos es el parámetro de profundidad máxima. Otro son las opciones de criterio: Gini/entropía (más tarde veremos más a fondo el criterio de entropía). Los hiperparámetros también ayudan a mejorar el modelo. Se pueden ajustar antes del entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9134ff2d",
   "metadata": {},
   "source": [
    "Los parámetros de un modelo determinan la manera en que un modelo hace predicciones.\n",
    "\n",
    " Los parámetros de un modelo son configuraciones que determinan la forma en que funciona un modelo.\n",
    "\n",
    "Los datos de entrenamiento afectan a los valores de los parámetros de un modelo.\n",
    "\n",
    "Los parámetros de un modelo están vinculados a los datos porque se generan durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9489385d",
   "metadata": {},
   "source": [
    "Echa un vistazo a un código ya conocido:\n",
    "\n",
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')\n",
    "\n",
    "Nuestra \"caja negra\" ya no es tan negra. Todos los hiperparámetros del algoritmo están dentro de los paréntesis. Ya conoces los criterios de profundidad máxima y Gini. También usaremos:\n",
    "\n",
    "- min_samples_split: Este hiperparámetro determina el número mínimo de observaciones que se deben tener en un nodo antes de que pueda dividirse. Su objetivo es evitar la creación de nodos que contengan un número insuficiente de observaciones del conjunto de entrenamiento.\n",
    "\n",
    "- min_samples_leaf: Este hiperparámetro establece el número mínimo de observaciones que debe tener una hoja, es decir, un nodo final sin divisiones. Su propósito es prevenir que el algoritmo genere nodos hoja con un número insuficiente de observaciones del conjunto de entrenamiento.\n",
    "\n",
    "Los valores de los hiperparámetros se establecen de forma predeterminada. No necesitas especificarlos pero puedes cambiarlos. Imagina que quieres preparar la receta de macarrones con queso de la abuela. Todos los ingredientes y las porciones están en una lista pero quieres sorprender a la abuela y hacerlos más cremosos, así que añades más queso. No sabes si a tu familia le gustará pero tienes la certeza de que has cambiado los hiperparámetros del plato. \n",
    "\n",
    "Para cada algoritmo, hay un conjunto específico de configuraciones que necesitas especificar antes del entrenamiento.\n",
    "\n",
    "\n",
    "¿Qué significa \"ajustar los hiperparámetros\"? \n",
    "\n",
    "Especificar manualmente las características del modelo antes del entrenamiento.\n",
    "\n",
    "¿Cuáles de estos son parámetros de un modelo? \n",
    "\n",
    "La profundidad del árbol de decisión\n",
    "\n",
    "    Tu conocimiento de la naturaleza del árbol de decisión es bastante profundo. Es una parte de la estructura del árbol entrenado.\n",
    "\n",
    "La característica que se usa en la condición del primer nodo.\n",
    "\n",
    "    Esta es parte de un árbol entrenado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fd83aa",
   "metadata": {},
   "source": [
    "### Ajuste de hiperparámetros\n",
    "\n",
    "Vamos a ajustar los hiperparámetros de nuestro árbol.\n",
    "\n",
    "El hiperparámetro más importante de un árbol de decisión es max_depth. Este determina qué obtendremos al final: un tocón con una pregunta o un arce con una enorme copa.\n",
    "\n",
    "¿Cómo podemos encontrar el mejor valor para el hiperparámetro max_depth si queremos mejorar el modelo? No lo sabemos de antemano. Así que iteraremos diferentes valores con un bucle y compararemos la calidad de las diferentes versiones del modelo. Lo comprobaremos automáticamente sin el conjunto de prueba.\n",
    "\n",
    "Ejercicio\n",
    "\n",
    "Cambia el hiperparámetro max_depthen el bucle de 1 a 5. Por cada valor, imprime la calidad para el conjunto de validación. Imprime esto en la pantalla:\n",
    "\n",
    "max_depth = 1 : ...\n",
    "max_depth = 2 : ...\n",
    "...\n",
    "max_depth = 5 : ...\n",
    "\n",
    "Aún no necesitamos probar nuestros modelos con el dataset de prueba. Primero seleccionaremos el mejor modelo.\n",
    "\n",
    "Termina el código del bucle:\n",
    "\n",
    "for depth in range(1, 6):\n",
    "        model = # < crea un modelo, especificar max_depth=depth >\n",
    "\n",
    "        # < entrena el modelo >\n",
    "\n",
    "        predictions_valid = # < encuentra las predicciones usando el conjunto de validación >\n",
    "\n",
    "        print(\"max_depth =\", depth, \": \", end='')\n",
    "        print(accuracy_score(target_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22228e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('/datasets/train_data_us.csv')\n",
    "df.loc[df['last_price'] > 113000, 'price_class'] = 1\n",
    "df.loc[df['last_price'] <= 113000, 'price_class'] = 0\n",
    "\n",
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345)\n",
    "\n",
    "features_train = df_train.drop(['last_price', 'price_class'], axis=1)\n",
    "target_train = df_train['price_class']\n",
    "features_valid = df_valid.drop(['last_price', 'price_class'], axis=1)\n",
    "target_valid = df_valid['price_class']\n",
    "\n",
    "# Create loop for max_depth from 1 to 5 >\n",
    "for depth in range(1,6):\n",
    "    # Crete model & specify max_depth=depth\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=12345)# < crea un modelo, especificar max_depth=depth >\n",
    "    # Train the model\n",
    "    model.fit(features_train, target_train)\n",
    "    # find the predictions using the validation set\n",
    "    predictions_valid =  model.predict(features_valid) # < encuentra las predicciones usando el conjunto de validación >\n",
    "\n",
    "    print('max_depth =', depth, ': ', end='')\n",
    "    print(accuracy_score(target_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2328dd3e",
   "metadata": {},
   "source": [
    "Output\n",
    "\n",
    "max_depth = 1 : 0.8522167487684729\n",
    "\n",
    "max_depth = 2 : 0.8522167487684729\n",
    "\n",
    "max_depth = 3 : 0.8466748768472906\n",
    "\n",
    "max_depth = 4 : 0.8725369458128078\n",
    "\n",
    "max_depth = 5 : 0.8663793103448276\n",
    "\n",
    "Hay tres cosas que podrías ver por siempre: una chimenea ardiendo, agua caer e hiperparámetros cambiar la calidad del modelo. \n",
    "\n",
    "Sin embargo, si el modelo no ha mejorado puede que sea buena idea dejarlo e intentar con otro."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
