{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3c9447",
   "metadata": {},
   "source": [
    "### Métricas de evaluación\n",
    "\n",
    "¿Cuál es la diferencia entre un buen modelo y uno malo? ¿Qué métricas debes elegir para evaluar un modelo?\n",
    "\n",
    "Las métricas de evaluación se utilizan para medir la calidad de un modelo y se pueden expresar numéricamente. Ya has encontrado una de estas métricas: exactitud. Hay otras, por ejemplo:\n",
    "\n",
    "- precisión (precision) toma todos los apartamentos que el modelo consideró caros (están marcados como \"1\") y calcula qué fracción de ellos era costosa realmente. Los apartamentos no reconocidos por el modelo se ignoran.\n",
    "\n",
    "- recall (sensibilidad) toma todos los apartamentos que son realmente caros y calcula qué fracción de ellos reconoció el modelo. Los apartamentos que fueron reconocidos por el modelo por error se ignoran.\n",
    "\n",
    "Veamos el siguiente ejemplo para comprender mejor estas métricas:\n",
    "\n",
    "Digamos que tienes un trabajo en un banco. El banco tiene 10 000 clientes. Sin embargo, 100 de ellos son estafadores, y tu trabajo es rastrearlos. El Clasificador A marca a 1000 clientes como posibles estafadores, pero solo 90 de ellos son estafadores reales. El Clasificador A tiene un recall alto (90%) porque logra encontrar a casi todos los estafadores, pero su precisión es baja (9%) ya que acusa erróneamente a cientos de ciudadanos honrados. Por otro lado, el Clasificador B marca a 10 clientes como estafadores, y 9 de ellos son realmente estafadores. Su recall es menor porque solo puede encontrar el 9% de ellos, pero la precisión es del 90% (¡9 de 10!).\n",
    "\n",
    "En otras palabras, recall es una prioridad cuando es importante encontrar todas las observaciones requeridas, incluso a costa de cometer muchos errores, y la precisión es importante cuando tu objetivo es minimizar los errores, incluso si eso significa que muchos casos no se detectan.\n",
    "\n",
    "Diferentes tareas requieren diferentes métricas de evaluación. ¿Por qué elegimos exactitud al determinar los precios de los apartamentos? Porque necesitamos tener en cuenta ambos tipos de errores (ceros que deberían ser unos, así como unos que deberían ser ceros), y eso es justo lo que hace la exactitud. Cada predicción incorrecta conduce a una recomendación incorrecta y a una posible pérdida de ganancias para el vendedor. A su vez, una mayor exactitud en la clasificación genera más ganancias. \n",
    "\n",
    "La alta calidad del modelo es algo bueno, pero su aplicación debe justificarse. Establezcamos los límites obvios. Si todas las respuestas son incorrectas, la exactitud es cero. Si todas las respuestas son correctas, es igual a uno. Por lo tanto, la exactitud no puede ser menor que cero ni mayor que uno. Si nuestro modelo tuviera una exactitud de 0.4, ¿su calidad se consideraría alta o baja?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab86f7f",
   "metadata": {},
   "source": [
    "Pregunta\n",
    "\n",
    "Supongamos que tenemos un modelo que asigna \"0\" o \"1\" al azar, con una probabilidad de 50/50. En otras palabras, el modelo \"adivina\" las respuestas en lugar de intentar hacer inferencias a partir de las características. ¿Cuál es la exactitud del modelo? Recordatorio: en esta tarea, el número de apartamentos en ambas clases es igual.\n",
    "\n",
    "Respuesta: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22f366",
   "metadata": {},
   "source": [
    "Consideremos las respuestas \"1\" (apartamentos caros) y \"0\" (apartamentos baratos) por separado:\n",
    "\n",
    "exactitud = 0.5 * (porcioˊn de adivinadas correctamente 1)+05 *(porcioˊn de adivinadas correctamente 0)\n",
    "exactitud=0.5 * (porcioˊn de adivinadas correctamente 1)+0.5 * (porcioˊn de adivinadas correctamente 0)\n",
    "\n",
    "Las respuestas del modelo no están vinculadas con las respuestas correctas, por lo que la probabilidad de adivinar \"1\" es del 50 % (lo mismo para \"0\"), lo que significa que la exactitud es de 0.5.\n",
    "\n",
    "exatitud=0.5⋅0.5+0.5⋅0.5=0.25+0.25 = 0.5 exatitud=0.5⋅0.5+0.5⋅0.5=0.25+0.25=0.5\n",
    "\n",
    "Cálculo detallado\n",
    "\n",
    "Si la exactitud es 0.4, ¿qué dice eso sobre la calidad del modelo? Es baja. Incluso adivinar al azar es mejor que eso.\n",
    "\n",
    "Siempre asegúrate de que tu modelo funcione mejor que la casualidad, es decir, realiza una prueba de cordura."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a003d617",
   "metadata": {},
   "source": [
    "### Métricas de evaluación en Scikit-Learn\n",
    "\n",
    "Sklearn tiene muchas funciones para calcular métricas, por lo que no tenemos que usar una fórmula para encontrar la exactitud.\n",
    "\n",
    "Las funciones métricas de la librería sklearn se encuentran en el módulo sklearn.metrics. Para calcular la exactitud utiliza la función accuracy_score().\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "La función toma dos argumentos (las respuestas correctas y las predicciones del modelo) y devuelve el valor de exactitud.\n",
    "\n",
    "accuracy = accuracy_score(target, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3ef859",
   "metadata": {},
   "source": [
    "¿La puntuación de exactitud difiere entre el conjunto de entrenamiento y el conjunto de prueba? Calcula los valores y muéstralos en la pantalla de la siguiente manera:\n",
    "\n",
    "Exactitud\n",
    "Training set: ...\n",
    "Test set: ...\n",
    "\n",
    "Guarda las predicciones en las variables train_predictions (para el conjunto de entrenamiento) y test_predictions (para el conjunto de prueba).\n",
    "\n",
    "La exactitud para el conjunto de entrenamiento se puede calcular de la siguiente manera:\n",
    "\n",
    "train_predictions = model.predict(features)\n",
    "accuracy_score(target, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('/datasets/train_data_us.csv')\n",
    "\n",
    "df.loc[df['last_price'] > 113000, 'price_class'] = 1\n",
    "df.loc[df['last_price'] <= 113000, 'price_class'] = 0\n",
    "\n",
    "features = df.drop(['last_price', 'price_class'], axis=1)\n",
    "target = df['price_class']\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=12345)\n",
    "\n",
    "model.fit(features, target)\n",
    "\n",
    "test_df = pd.read_csv('/datasets/test_data_us.csv')\n",
    "\n",
    "test_df.loc[test_df['last_price'] > 113000, 'price_class'] = 1\n",
    "test_df.loc[test_df['last_price'] <= 113000, 'price_class'] = 0\n",
    "\n",
    "test_features = test_df.drop(['last_price', 'price_class'], axis=1)\n",
    "test_target = test_df['price_class']\n",
    "\n",
    "train_predictions = model.predict(features)\n",
    "test_predictions = model.predict(test_features)\n",
    "\n",
    "train_accuracy = accuracy_score(target, train_predictions)\n",
    "test_accuracy = accuracy_score(test_target, test_predictions) \n",
    "\n",
    "print('Exactitud')\n",
    "print('Training set:', train_accuracy)\n",
    "print('Test set:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a343d8e6",
   "metadata": {},
   "source": [
    "Resultado\n",
    "\n",
    "Exactitud\n",
    "Training set: 0.9998460354118552\n",
    "Test set: 0.5756172839506173"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
